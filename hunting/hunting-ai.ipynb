{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd568747-675f-4562-ac28-2cc6ff87daf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "import requests\n",
    "\n",
    "pd.set_option('display.max_columns', None)      # Show all columns\n",
    "pd.set_option('display.max_colwidth', None)     # Don't truncate column content\n",
    "pd.set_option('display.expand_frame_repr', False)  # Prevent wrapping to new lines\n",
    "print(\"Current working directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2dd2d8-6e7e-44a7-b826-f3b278b534a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "process_logs_dir = 'tmp-process'\n",
    "network_logs_dir = 'tmp-network'\n",
    "\n",
    "# Helper: parse a single log line into a dictionary\n",
    "def parse_log_line(line):\n",
    "    pattern = r'(\\w+):\\s([^|]+)'\n",
    "    matches = re.findall(pattern, line)\n",
    "    return {k.strip(): v.strip() for k, v in matches}\n",
    "\n",
    "# Helper: read and parse all logs in a given directory\n",
    "def read_logs_from_directory(log_dir):\n",
    "    parsed_logs = []\n",
    "    for filename in os.listdir(log_dir):\n",
    "        filepath = os.path.join(log_dir, filename)\n",
    "        if os.path.isfile(filepath):\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                for line in f:\n",
    "                    line = line.strip()\n",
    "                    if line:\n",
    "                        parsed_logs.append(parse_log_line(line))\n",
    "    return parsed_logs\n",
    "\n",
    "\n",
    "process_events = read_logs_from_directory(process_logs_dir)\n",
    "network_events = read_logs_from_directory(network_logs_dir)\n",
    "df_process = pd.DataFrame(process_events)\n",
    "df_network = pd.DataFrame(network_events)\n",
    "df_combined = pd.concat([df_process, df_network], ignore_index=True)\n",
    "df_combined['timestamp'] = pd.to_datetime(df_combined['timestamp'], errors='coerce')\n",
    "df_combined = df_combined.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee8d0a0-e015-4099-9b0e-0d9d93b1fa87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "column_order = [\n",
    "    \"timestamp\", \"event\", \"hostname\", \"username\", \"pid\", \"process\", \"ppid\",\n",
    "    \"parent\", \"sourceip\", \"sourceport\",\n",
    "    \"destip\", \"destport\", \"status\", \"sid\"\n",
    "]\n",
    "for col in column_order:\n",
    "    if col not in df_combined.columns:\n",
    "        df_combined[col] = \"\"\n",
    "\n",
    "df_combined = df_combined[column_order]\n",
    "df_combined = df_combined.fillna(\"\")\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca424f4e-e113-4a0e-a8f4-7229274f166e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Available fields:\\n\", list(df_combined.columns))\n",
    "\n",
    "field = input(\"\\nEnter field to search (e.g., name, process, destip): \").strip()\n",
    "if field not in df_combined.columns:\n",
    "    print(f\"Field '{field}' not found. Please choose from the list above.\")\n",
    "else:\n",
    "    value = input(\"Enter value to search for (partial match okay): \").strip()\n",
    "    result = df_combined[df_combined[field].str.contains(value, case=False, na=False)]\n",
    "    print(f\"\\nFound {len(result)} matching rows:\\n\")\n",
    "    display(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55cef6d-1a31-4467-a32b-8fddc58d1b84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Process outliers\n",
    "process = (\n",
    "    df_combined\n",
    "    .groupby(['process', 'parent', 'event'])\n",
    "    .size()\n",
    "    .reset_index(name='count')\n",
    "    .sort_values(by='count', ascending=True)\n",
    ")\n",
    "processhunt = (\n",
    "    process[process['event'] == 'process created']\n",
    "    .head(10)\n",
    ")\n",
    "processhunt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e99cba-7171-4949-8320-ae586cae5820",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# User outliers\n",
    "users = (\n",
    "    df_combined\n",
    "    .groupby(['username', 'process', 'event'])\n",
    "    .size()\n",
    "    .reset_index(name='count')\n",
    "    .sort_values(by='count', ascending=True)\n",
    ")\n",
    "userhunt = users[users['event'] == 'process created'].head(10)\n",
    "userhunt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d978649f-c9d0-4226-a987-c2e3e119fdd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "process_sample = processhunt  \n",
    "users_sample = userhunt     \n",
    "\n",
    "process_csv = process_sample.to_csv(index=False)\n",
    "users_csv = users_sample.to_csv(index=False)\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Process data contains process parent and child relationship outliers. User data contains user and process\n",
    "outliers. These are the outliers from a set of process logs. The field are as follows:\n",
    "process is the name of the process that ran. parent is the name of the parent process that created it.\n",
    "username is the user context that the process ran under.\n",
    "event is the event type; this is less important.\n",
    "As a threat hunter, analyze the following process and user log data for suspicious or anomalous behavior. \n",
    "Highlight any unusual process creations, rare parent-child relationships, or frequencies, considering how \n",
    "rare the outlier events may be. Keep in minf that the 'process' field is the process name and the 'parent' field \n",
    "is the name of the parent process that started the process in the 'process' field. Analyze every line\n",
    "and suggest up to three log lines to investigate. \n",
    "which are the most anomalous and give suggested investigation steps. Do not tell me about normal or \n",
    "unremarkable events.\n",
    "\n",
    "Process Data:\n",
    "{process_csv}\n",
    "\n",
    "User Data:\n",
    "{users_csv}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5199728-34b7-4ac8-82a8-eccd7a1e721b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "GROQ_API_URL = \"https://api.groq.com/openai/v1/chat/completions\"  # Replace with actual endpoint if different\n",
    "GROQ_API_KEY = \"INSERT-KEY-HERE\"  # Replace with your actual API key\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {GROQ_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "data = {\n",
    "    \"model\": \"gemma2-9b-it\",  # Replace with your desired Groq model\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    #\"max_tokens\": 1024  # Adjust as needed\n",
    "}\n",
    "\n",
    "response = requests.post(GROQ_API_URL, headers=headers, json=data)\n",
    "result = response.json()\n",
    "print(result['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a69d81b-acbb-4f38-bad9-ba44b1a2baf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
