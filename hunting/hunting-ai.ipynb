{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd568747-675f-4562-ac28-2cc6ff87daf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "import requests\n",
    "\n",
    "pd.set_option('display.max_columns', None)      # Show all columns\n",
    "pd.set_option('display.max_colwidth', None)     # Don't truncate column content\n",
    "pd.set_option('display.expand_frame_repr', False)  # Prevent wrapping to new lines\n",
    "print(\"Current working directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2dd2d8-6e7e-44a7-b826-f3b278b534a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "process_logs_dir = 'process'\n",
    "network_logs_dir = 'network'\n",
    "\n",
    "# Helper: parse a single log line into a dictionary\n",
    "def parse_log_line(line):\n",
    "    pattern = r'(\\w+):\\s([^|]+)'\n",
    "    matches = re.findall(pattern, line)\n",
    "    return {k.strip(): v.strip() for k, v in matches}\n",
    "\n",
    "# Helper: read and parse all logs in a given directory\n",
    "def read_logs_from_directory(log_dir):\n",
    "    parsed_logs = []\n",
    "    for filename in os.listdir(log_dir):\n",
    "        filepath = os.path.join(log_dir, filename)\n",
    "        if os.path.isfile(filepath):\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                for line in f:\n",
    "                    line = line.strip()\n",
    "                    if line:\n",
    "                        parsed_logs.append(parse_log_line(line))\n",
    "    return parsed_logs\n",
    "\n",
    "\n",
    "process_events = read_logs_from_directory(process_logs_dir)\n",
    "network_events = read_logs_from_directory(network_logs_dir)\n",
    "df_process = pd.DataFrame(process_events)\n",
    "df_network = pd.DataFrame(network_events)\n",
    "df_combined = pd.concat([df_process, df_network], ignore_index=True)\n",
    "df_combined['timestamp'] = pd.to_datetime(df_combined['timestamp'], errors='coerce')\n",
    "df_combined = df_combined.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3160f6-1067-486c-b335-6a6ef847e54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee8d0a0-e015-4099-9b0e-0d9d93b1fa87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "column_order = [\n",
    "    \"timestamp\", \"event\", \"hostname\", \"username\", \"pid\", \"process\", \"ppid\",\n",
    "    \"parent\", \"cmdline\", \"sourceip\", \"sourceport\",\n",
    "    \"destip\", \"destport\", \"status\", \"sid\"\n",
    "]\n",
    "for col in column_order:\n",
    "    if col not in df_combined.columns:\n",
    "        df_combined[col] = \"\"\n",
    "\n",
    "df_combined = df_combined[column_order]\n",
    "df_combined = df_combined.fillna(\"\")\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca424f4e-e113-4a0e-a8f4-7229274f166e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Available fields:\\n\", list(df_combined.columns))\n",
    "\n",
    "field = input(\"\\nEnter field to search (e.g., name, process, destip): \").strip()\n",
    "if field not in df_combined.columns:\n",
    "    print(f\"Field '{field}' not found. Please choose from the list above.\")\n",
    "else:\n",
    "    value = input(\"Enter value to search for (partial match okay): \").strip()\n",
    "    result = df_combined[df_combined[field].str.contains(value, case=False, na=False)]\n",
    "    print(f\"\\nFound {len(result)} matching rows:\\n\")\n",
    "    display(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0b3d66-8b7b-4f57-9627-640529fb7c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00081256-962b-4027-b8ad-de55ee6c4131",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_process['parent'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d18ddfe-307b-4462-ae29-a3ab59795ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_process['name'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13ea307-7922-425d-98f8-fff6850c9223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize 'name' to catch all variations of bash\n",
    "process['name_clean'] = process['name'].str.strip().str.lower()\n",
    "\n",
    "# Filter for combinations where:\n",
    "# - the event is 'process created'\n",
    "# - OR the name ends with 'bash' (e.g., '/bin/bash')\n",
    "filtered = process[\n",
    "    (process['event'] == 'process created') |\n",
    "    (process['name_clean'].str.endswith('bash'))\n",
    "]\n",
    "\n",
    "# Sort by count to get the rarest combinations\n",
    "processhunt = filtered.sort_values(by='count', ascending=True).head(10)\n",
    "\n",
    "# Show the results\n",
    "processhunt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55cef6d-1a31-4467-a32b-8fddc58d1b84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Process outliers\n",
    "process = (\n",
    "    df_process\n",
    "    .groupby(['name', 'username', 'cmdline', 'event',])\n",
    "    .size()\n",
    "    .reset_index(name='count')\n",
    "    .sort_values(by='count', ascending=True)\n",
    ")\n",
    "processhunt = (\n",
    "    process[process['event'] == 'process created'] |\n",
    "    process[process['name'] == 'bash']\n",
    "    .head(10)\n",
    ")\n",
    "processhunt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e99cba-7171-4949-8320-ae586cae5820",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# User outliers\n",
    "users = (\n",
    "    df_combined\n",
    "    .groupby(['username', 'process', 'event'])\n",
    "    .size()\n",
    "    .reset_index(name='count')\n",
    "    .sort_values(by='count', ascending=True)\n",
    ")\n",
    "userhunt = users[users['event'] == 'process created'].head(10)\n",
    "userhunt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d978649f-c9d0-4226-a987-c2e3e119fdd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "process_sample = processhunt  \n",
    "users_sample = userhunt     \n",
    "\n",
    "process_csv = process_sample.to_csv(index=False)\n",
    "users_csv = users_sample.to_csv(index=False)\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Process data contains process parent and child relationship outliers. User data contains user and process\n",
    "outliers. These are the outliers from a set of process logs. The field are as follows:\n",
    "process is the name of the process that ran. parent is the name of the parent process that created it.\n",
    "username is the user context that the process ran under.\n",
    "event is the event type; this is less important.\n",
    "As a threat hunter, analyze the following process and user log data for suspicious or anomalous behavior. \n",
    "Highlight any unusual process creations, rare parent-child relationships, or frequencies, considering how \n",
    "rare the outlier events may be. Keep in minf that the 'process' field is the process name and the 'parent' field \n",
    "is the name of the parent process that started the process in the 'process' field. Analyze every line\n",
    "and suggest up to three log lines to investigate. \n",
    "which are the most anomalous and give suggested investigation steps. Do not tell me about normal or \n",
    "unremarkable events.\n",
    "\n",
    "Process Data:\n",
    "{process_csv}\n",
    "\n",
    "User Data:\n",
    "{users_csv}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5199728-34b7-4ac8-82a8-eccd7a1e721b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "GROQ_API_URL = \"https://api.groq.com/openai/v1/chat/completions\"  # Replace with actual endpoint if different\n",
    "GROQ_API_KEY = \"INSERT-KEY-HERE\"  # Replace with your actual API key\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {GROQ_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "data = {\n",
    "    \"model\": \"gemma2-9b-it\",  # Replace with your desired Groq model\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    #\"max_tokens\": 1024  # Adjust as needed\n",
    "}\n",
    "\n",
    "response = requests.post(GROQ_API_URL, headers=headers, json=data)\n",
    "result = response.json()\n",
    "print(result['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a69d81b-acbb-4f38-bad9-ba44b1a2baf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your log file\n",
    "logfile = 'services'\n",
    "\n",
    "# Read and parse each line\n",
    "def parse_log_line(line):\n",
    "    record = {}\n",
    "    parts = [part.strip() for part in line.strip().split('|')]\n",
    "    for part in parts:\n",
    "        if part.startswith(\"uuid: \"):\n",
    "            key, val = part.split(\": \", 1)\n",
    "            record[key] = literal_eval(val)\n",
    "        else:\n",
    "            key, val = part.split(\": \", 1)\n",
    "            record[key] = val\n",
    "    return record\n",
    "\n",
    "# Open file and parse lines\n",
    "with open(logfile, 'r') as f:\n",
    "    parsed_logs = [parse_log_line(line) for line in f if line.strip()]\n",
    "\n",
    "# Convert to DataFrame\n",
    "services = pd.DataFrame(parsed_logs)\n",
    "\n",
    "# Flatten the 'uuid' dictionary column\n",
    "if 'uuid' in df.columns:\n",
    "    uuid_df = df['uuid'].apply(pd.Series)\n",
    "    services = services.drop(columns=['uuid']).join(uuid_df)\n",
    "\n",
    "# Display or use the DataFrame\n",
    "services\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d94dd21c-5a18-444f-878d-a0349a0a5491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### 🧠 LLM Response\n",
       "\n",
       "**Unique Services:**\n",
       "There are 64 unique services listed in the provided log data.\n",
       "\n",
       "**Most Inexplicable or Indicative of Potential Compromise:**\n",
       "After reviewing the log data, I would highlight the `iocontrol` service as the most inexplicable or indicative of potential compromise.\n",
       "\n",
       "**Reasoning:**\n",
       "The `iocontrol` service is listed as \"loaded (failed)\" twice, with the same timestamp and UUID. This suggests that the service failed to start or load, but the exact reason for the failure is not provided. The fact that the service is listed as \"failed\" twice, with the same timestamp, raises suspicions about its legitimacy.\n",
       "\n",
       "Additionally, the service name \"iocontrol\" is not a standard or well-known service on Linux systems. This could indicate that the service is custom or malicious, and its presence on the system may be a sign of compromise.\n",
       "\n",
       "**Why it's unusual:**\n",
       "The `iocontrol` service is unusual because:\n",
       "\n",
       "1. It's not a standard or well-known service on Linux systems.\n",
       "2. It failed to start or load twice, with the same timestamp and UUID.\n",
       "3. The exact reason for the failure is not provided.\n",
       "4. The service name \"iocontrol\" is not descriptive or informative.\n",
       "\n",
       "Overall, the presence of the `iocontrol` service, with its unusual name and failure to start or load, raises suspicions about its legitimacy and may indicate potential compromise."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Assume your DataFrame is called `services`\n",
    "# Convert to a readable string (e.g., table or JSON)\n",
    "data_str = services.to_string(index=False)\n",
    "\n",
    "# Define your prompt\n",
    "prompt = f\"\"\"\n",
    "You are a cybersecurity threat hunter. First, tell me how many unique services you see.\n",
    "Next, consider each line in the log data. Given the following list of Linux service events, \n",
    "identify ONE service that is the most inexplicable or indicative of potential compromise. \n",
    "Provide reasoning for any services you highlight and explain why they are unusual. Ignore services\n",
    "you recognize as legitimate.\n",
    "\n",
    "Service Data:\n",
    "{data_str}\n",
    "\"\"\"\n",
    "\n",
    "# GROQ API request setup\n",
    "groq_api_key = \"KEY\"\n",
    "model = \"llama-3.1-8b-instant\"  # or llama3-70b or gemma-7b depending on your setup\n",
    "\n",
    "url = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {groq_api_key}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "payload = {\n",
    "    \"model\": model,\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a cybersecurity threat hunter.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    \"temperature\": 0.3\n",
    "}\n",
    "\n",
    "# Send request\n",
    "response = requests.post(url, headers=headers, json=payload)\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "if response.ok:\n",
    "    content = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    display(Markdown(f\"### 🧠 LLM Response\\n\\n{content}\"))\n",
    "else:\n",
    "    print(\"❌ Error:\", response.status_code)\n",
    "    print(response.text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea4ccaa-90e6-4791-ba91-8c0ac28cfd2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8131c7-5bed-4c4a-823b-69ec4027120b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
